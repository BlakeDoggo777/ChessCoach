Test cases
- see if we can test predictions and validate loss functions

Next
- separate binary output paths
- limit prediction caching to ply 6, perf(6) = 119,060,324
- run some validation on policy loss - it's always so low
- try to get tensorboard integrated - can probably just log from py training code
- try squeeze/excite
	- once data is better for convergence and tensorboard is up, compare
- try v2 residuals
- try some additional curriculum heads; e.g. autoencode position, or count piece types, or linear material imbalance
- try Wu improvements (accelerating go learning)
- experiment with endgame tablebases integrated

Performance
- break down MCTS timing details just in case anything's off (just use sampling)
- try 16-bit for self-play - need to look up weight compatibility
- try use inline map in Node rather than heap-allocated (limit to 80? 480 extra bytes plus overhead)
	- maybe just linear lookup, no log-time involved? investigate by-key vs. iteration cases
	- can always binary search Move-ints or something too, it's not mutated
- load games faster - overlapped I/O?
- check inlining once CPU tree is looking good
- try Intel compiler in future

Training quality
- turn down the stockfish eval blend factor as training progresses
- run tournaments against stockfish or something known/lower to estimate Elo
- Integrate Strategic Test Suite (STS) - wait for UCI first or no?

Code quality
- unify config across C++/Python
- privatize C++ methods (got too python-brained)

Scalability
- can't play enough self-play games, work on new ideas soon
- can't afford 1 million games in the window (RAM or disk), work something out

Python
- Add type info everywhere - look up best practices for linting etc.

Improvements
- Multi-thread MCTS, if not for self-play generation then for UCI play
	- "On the scalability of parallel UCT"
	- https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e
- "Random move with eval within 1%"
	- http://blog.lczero.org/2018/12/alphazero-paper-and-lc0-v0191.html?m=1
	- https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd

UCI
- Wrap the C++ with UCI now
	- Need to make TF/etc. silent
	- Work out own threading mechanism or piggyback on Stockfish's if possible
- Implement infinite think, ponder, time controls
- Implement endgame tablebases (invisible/external to the training loop?)
- Switch from python-chess to own board, movegen, etc. (or be sure of GPLv3 static vs. dynamic)

Deployment
- add linux support
- installers, instructions, progress indicators, error handling, etc.

Low priority
- see if it's more efficient saving/loading checkpoints (measure save/load time, prediction time, disk savings)
- 80 cap on branched moves w/ cache may be a problem later; applies before d-noise, so limits exploration
- structured binding, check all pairs

Revisit
- try batch renorm + ghost batch norm
	- Bug: https://github.com/tensorflow/tensorflow/issues/32380