Training runs
- run new baseline (selfplay4) to give comparable STS rating after PUCT/UCI changes
- evaluate SE/pooling (read over 2f/2d notes)
- run raw student-as-teacher, make sure distillation is worth it
	- try dense layer in policy head for student network (may not be enough depth for convolutions)
- run 1 vs. 8 vs. 32 value head filters

Student training
- make student prefer matching teacher for repeatability
- try low-hanging fruit on self-play network/data, e.g. higher learning rate

Quality
- remove hybrid supervised/self-play infra
- factor out bucket name from docker scripts

Criticality training (shelved)
- add to GUI, look over saved positions, decide whether to drive 800-1600 range
- either pull in whole change or some of the code cleanup
	- logging wrong loss to tensorboard in shelved commit, fix
	- add unit test for criticality training target via decompress API


Training improvements
- add domain features (e.g. piece counts, fading king positions)
- SE (lc0)
	- try batchnorm/relu before SE since we have v2 residuals
- SE-ish-as-bias (Wu)
	- (TODO)
- playout cap randomization (Wu)
- pseudonegatives (look up the paper again, may be difficult/impossible for chess, invalid positions)
- try 1 vs. 8 vs. 32 value head filters again
	- lc0/Wu seem to use similar conv filters for policy and value heads?
	- lc0 was thinking fully connected layer may be needed for policy head when network isn't deep enough to cross board well (may not apply for distillation)
- try a run with masked policy loss (valid moves only) once there's enough data to compare
	- could also conceivably blend, like 1.0 for legal moves and 0.15 zero-pressure for others
- sketch out "value trust curve", especially with volatile game, multiple mistakes both sides
	- work out static eval vs. search on stockfish side for inflection/control points, see what's viable
- investigate FROST - need to read more, but applied to data efficiency, seems like we could go in a couple directions:
	- use as intended, grab a bunch of unlabeled games, gradually pseudo-label better (end up with more data)
	- treat existing labels as pseudo-labels (e.g. poor-confidence value-from-final-result) and refine (end up with improved label quality)

Training - later
- try out "sleeping" in the rotation - train random noise, different distributions
- Try knowledge distillation for regression ideas: http://www.cs.ox.ac.uk/files/11078/ICCV19_Distilling_Knowledge_From_a_Deep_Pose_Regressor_Network.pdf
- like Wu/lc0/SAI, think about finish-fast utility score added to win score - way later though, only useful if it plays well but dithers
- stochastic weight averaging
- move to ~100MB-sized chunks as recommended (but make sure self-play can still viably train)

Prediction cache
- investigate collisions (non-transposition style) during single search UCI affecting value convergence (details in 1/28 notes)
- test for average strength gain/loss ignoring path dependence and using in UCI/strengthtest for transpositions
	- no gain/loss earlier, try again after more PUCT work that does better for more nodes
- test speed gain for self-play generation ignoring path dependence, transposition table-style
- try stockfish-style prefetch asap after hash key update
- any more cache tuning? - hits about 70% full 40% hit rate after 3142 games, 12 ply max
	- while not full hit rate should be higher? add some new metrics
	- can probably remove max-ply if switching to transposition style - clear probe metrics after ramp-up, then measure

PUCT - medium confidence
- try scale FPU up over time, gives exhaustive coverage, can use checks/winning captures heuristic and prior to differentiate
	- try hard exhaustive term (e.g. 1 per child after N visits)
- try value stddev
- try decouple linear term from value/prior deltas - not enough pure linear, not enough backprops in low-value-squish subtrees
	- causes scrambling at low value squish, even prior exploration term maybe
	- look at 2r2rk1/1b2qppp/pp3n2/n2p4/P2N4/RPN1P3/2Q1BPPP/5RK1 w - - 1 17 (need to find b4)
- try elimination
- try softer backprop weights (e.g. help with 0.77 vs. 0.78 value example - although threshold with hard weights may still work there)
- last all-out attempt at position #3 before returning to 800 training target and actual training again
	- try last-value again but scaled down (constant or f(n))
	- try killer heuristic for mate-in-N only - good examples in Arasan21 position #3 underneath Rf6, have to prove that many moves are losing

PUCT - low confidence
- try sufficiency threshold or minimum value delta
- try use virtual loss only for selection PUCT, not for AZPUCT/backprop-check (lose a lot of backprops, probably not viable)
- try integrate trained criticality back in

PUCT - expensive/failed ideas
- catch up on unpropagated value when returning via AZPUCT (+upSum, +upWeight)
- regret-pruning (+upSum, +upWeight)
- RAVE term, decaying with exploration (+amafSum, +amafWeight)

PUCT - finishing
- ablate PUCT terms, trim down to just parallelism/mate improvements, confidently measure what helps
- CPU-optimize: e.g. can calculate global exploration factor much less often, much more required with new terms
- see if there's enough speedup from cache-aligning nodes and just paying for the extra self-play memory
	- (assume not because we usually need to visit a bunch of children at once; depends on isolated parent access)
- need long long search time parameter optimization for 1.25+ constant, e.g. applying similar to new terms

PUCT - training
- see if anything helps 800 node range (i.e. optimize parameters with nodes=800), or 1600, etc.

PUCT - later
- try use saturation point of visits/ucb to extend 800 simulations or UCI time control if visits would exceed current best
	- could this also be used earlier during search, backpropagate up a pending/bounty value via separate field to be replaced
	  by actual backprops - set it up when saturation point would take from below 1st to 1st in visits

PUCT questions
- force AZPUCT in search path after first non-AZPUCT choice?
- accept damaging 800-node distribution and prune aggressively to compensate?

GUI
- invert uci/gui relationship after working out in-proc/out details
	- switch between database/UCI modes
	- browse EPDs
	- set up positions (paste pgn, fen, move pieces, uci from database position)
	- go X buttons
	- drill into moves to see deeper breakdowns during UCI (like ~ ucb moves ...)
- deal with info panel height/scrolling, move list
- change the square background rather than adding overlay, need more consistency between black/white squares
- websocket reconnect

Quality
- modify config.toml directly in sub-dockerfiles, don't rebuild/reinstall
- print config summary when starting a run

Commentary
- try tf.text, see if 2.4.0 is supported on Windows or 2.4.1 needed (sub-word tokenization)
- read up on "learning without forgetting"
- try BERT/GPT-2, check out huggingface
- better prediction code, top-k or w/e rather than greedy (not beam search, has issues)
- bring back network.js cleanup from stashed fit() port
- clean away transformer.js and any other danging .js (tensor2tensor?)
- try time and special-case speed-up prediction for batchsize=1
- basic - does the encoder need an extra dense+relu layer after the tower/reshape?
- think about 1D vs. 2D again: https://arxiv.org/pdf/1502.03044.pdf
- read about "Performer" architecture
- read about PET: https://arxiv.org/pdf/2001.07676.pdf
- find more training data
- build deterministic train/validate split (e.g. in Pgn tool that reads/dumps)
- try encode before-and-after positions (no flip?) - comment on the move, not the position
	- yes, image takes last N positions, but network is trained to evaluate the position, not the delta

Cluster
- validation log still 11-12s after training log on cluster, try prefetch harder or debug

UCI (#2)
- manually dig into/debug STS strength drop with higher parallelism (1*16 vs. 2*256)
- already forcing value() for proved mate/opponent mate, but investigate positions and see whether mate term still helps M3 vs. M2, etc.
	- read over notes from initial work there, check for pitfalls
	- try no exploration terms for opponent-mate (test position: 6k1/4pppp/3B4/8/8/8/5PPP/R5K1 b - - 0 0)
	- try to make mate-visiting stop wasting time, instantly push up until an ancestor down to 2nd best
		- complicated with multiple levels of visits
		- complicated if 2nd best is also mate/terminal
		- only count as UCI "node" when expanding, not when terminal - same with initial expansions? - same with simulation count (800)?
- (still needed?) try out a backtracking implementation of virtual exploration/loss that goes as deep
	  as it can into good lines and can choose between 2nd best here vs. 2nd best up one level, etc.,
	  choosing better nodes overall and avoiding failed simulations
- (does this make any sense?) try speculative budgeting in addition to virtual exploration/loss
	- for N+small delta, which would have UCB > current best
	- can we still speculatively backprop, and is it needed after introducing scaled virtual loss
- profile CPU again
- tail Backpropagate into BackpropagateVisitsOnly
- basic improvements to time control
	- badly need to play well with X moves in Y, "movestogo", loses games vs. stockfish
	- don't waste time when only 1 or few legal moves
	- if dangerous time left, take mate-in-N rather than trying to find faster

CPU+GPU integration performance:
- try vectorize/GPU softmax/UCT calcs
- break down MCTS timing details just in case anything's off (instrumented, already did some sampling measurements/optimization)
- image key for prediction cache can be incrementally updated if it helps enough
- for Nodes can point last sibling at root and unrecurse deletion (sacrificing breadth-at-once)

Code quality
- either remove dataset/training mixing (C++/Python) or fix "ValidateSchedule" to handle division factor
- try multistage docker build, debian only for building chesscoach, copy over to tensorflow base
- inject config.toml into cluster volume, take out of image tags, make sure it takes priority over installed
- copy config.toml from install->user on run (if not present) - optimized for dev iteration atm
- switch to vcpkg for windows dependencies
- fix _ in network names - split on final _
- factor out all-exist ringbuffer with foreach iteration (begin/end)
- privatize C++ methods (got too python-brained)
- try split up MCTS vs. selfplaygames better - e.g. maybe move softmax/selectmove out? separate files?
- try split SelfPlayGame/Worker vs. "UciGame/Worker" better somehow (including image/value/policy arrays, batch sizes, etc.)
- add Python type info everywhere - look up best practices for linting etc.
- check for any unnecessary move constructors
- add further architecture configuration to toml config (residuals*filters, etc.)
- switch to sample ratio, rather than specifying games + steps (complicated, ties in to "curriculum schedule" in config maybe)
- StrengthTestNetwork (naming)

UCI (#3)
- mate
	- if root node's terminal value is known, and allowed to stop searching, make a move instantly and save time
	- add global depth cut-off (a little tricky, need to allow MCTS to "back up" and ban paths that don't reach a leaf in time)
	- add killer heuristic (needs to vanish quickly with exploration)
		- test with M1 position with M1 prior artifically set low for ply 0
		- also strength-test
	- forced draw propagation if it'll help
- look into LCB move selection (Wu, LZ)
- implement worthwhile options (work out hash, TT vs. prediction cache)
- workaround for .exe vs. non in ChessBase, test as kibitzer
- implement proper time controls/search options, ponder

Finalizing training
- work out learning rate schedule to fine-tune with final self-play budget known

Deployment
- installers, instructions, progress indicators, error handling, etc.
- linux unit test script
- add windows command line build script, binplace somewhere cleanly

Publishing
- write-ups
- website - game-in-10, one at a time, people can watch, comments shown for each move

Bugs
- Some kind of race condition spamming next-chunk button in GUI, locks up Python/C++ interop
- Close cleanly if selfplay/UCI network not found by name in config list, in Python or C++
- SelfPlayWorker objects are created on the main thread and use its StateInfo in Game::Game(), then the worker thread steals in Free
- Rare ephemeral storage issue on cluster, might be core dumps
- Tiny configs with self-play don't work now with minimum 2000 chunking
- Tests need to set CHESSCOACH_SILENT before initializing python somehow (mostly for NetworkTest.cpp)

Low priority
- shouldn't use prediction cache with uniform predictions (CPU) - ugly to plumb
- save fewer networks to cloud storage or cull old ones in between strength tests or something - 100 MB per save
- structured binding, check all pairs

Won't do
- TensorRT or TF C++ API (overly complicated setup, especiallly building TF on Windows, embarrassingly bad)
- Richer UCI features like multiPV or ponder
- endgame tablebases (e.g. leveraging Stockfish probing code)
	- UCI: not interesting enough, others can add if going for pure strength
	- Training: complicated, scope too large - self-play needs to make mistakes to learn imbalances