Porting
- Get play/train loop working - need to pass games back, orchestrate it all
- Delete Python self-play code when ready
- Check for Python interop leaks (audit refcounting)

C++
- Eventually modify stockfish - Position, etc. - so it doesn't reach out to uci/options/threads code at all
- Validate that SelfPlay.cpp draw checking is valid (re: ply) - step through basic + triangulation examples from starting position with knights
- Turn 12/8/8, 73/8/8 everywhere into constexpr
- Compile with AVX (2?), benchmark

Basic loop
1) Roughly proportion self-play to training ratio
2) Get multiple self-play workers running and batching their predictions
3) Add additional input planes (beyond just pieces) once basic loop is working
4) Maybe make self-play/training workers use an --arg which also makes TF chatty (vs. UCI mode by default with no args)

Longer training
1) Save/load generated games
2) Save/load network

Improvements
- Multi-thread MCTS, if not for self-play generation then for UCI play
	- "On the scalability of parallel UCT"
	- https://medium.com/oracledevs/lessons-from-alpha-zero-part-5-performance-optimization-664b38dc509e
- "Random move with eval within 1%"
	- http://blog.lczero.org/2018/12/alphazero-paper-and-lc0-v0191.html?m=1
	- https://kstatic.googleusercontent.com/files/2f51b2a749a284c2e2dfa13911da965f4855092a179469aedd15fbe4efe8f8cbf9c515ef83ac03a6515fa990e6f85fd827dcd477845e806f23a17845072dc7bd

UCI
- Integrate sync-UCI hack with trained model
- Split out UCI thread so infinite think, ponder, etc. can workers
- Implement infinite think, ponder, time controls
- Implement endgame tablebases (invisible/external to the training loop?)
- Switch from python-chess to own board, movegen, etc. (or be sure of GPLv3 static vs. dynamic)