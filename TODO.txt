Training - final run
- use student prediction the whole way this time, up to 2.8m steps, see if it hits 3.3k STS rating
- copy network/games up to 800k steps to 9a or w/e and start a teacher-only/SWA prediction run from there up to 2.8m steps
- if same take original else teacher-only up to 5.6m

Commentary training
- update training data for new filter after comparisons finished, sync tokenizer
- choose commentary_steps config to stop after
- compare with shelved double-encode (may need another range test)

Commentary quality
- vary top_p value
- vary temperature

PUCT - medium confidence
- try prior flattening/absolute linear (still respect value) with high nodes again, despite linear
	- 3qkb1r/3n1ppp/R1Npp3/6P1/QPr2P2/2P5/7P/4R1K1 b k - 2 27 - need Rxc6, avoid Qc8
	- kr6/ppq3b1/2pNQ1p1/7p/7P/1R4P1/P4PB1/3n2K1 w - - 0 32 - find Rxb7 M10 - gets stuck on Ne8
	- can also help more backprops go to value rather than value+prior at high node counts
- try blend in prior softening towards endgame
	- 8/2Q5/8/2k5/6K1/8/3r4/q7 b - - 38 113 - avoid Kd4 - work around overly sharp priors
- try scale FPU up over time, gives exhaustive coverage, can use checks/winning captures heuristic and prior to differentiate
	- try hard exhaustive term (e.g. 1 per child after N visits - maybe M grandparent visits)
	- 8/8/8/2P3R1/5B2/2rP1p2/p1P1PP2/RnQ1K2k w Q - 5 3 - find M2
- try value stddev
- last all-out attempt at position #3
	- try last-value again but scaled down (constant or f(n))
	- try killer heuristic for mate-in-N only - good examples in Arasan21 position #3 underneath Rf6, have to prove that many moves are losing - decay
		- could be mate-in-N or syzygy lower bound or just really high value threshold? only 1 killer move, best
		- could implement simply using FPU-weight
- think of ways to catch up visits when suddenly finding value at very high nodes
	- some kind of high-trust/verification PUCT saturation calc?
	- backpropagate more than 1 weight/visit per, for high overall visits + deep leaf?
- work on making more progress in endgames - may be worse now with higher NPS from cache-as-TT
	- 8/8/8/4ppk1/8/8/6K1/8 b - - 0 84

PUCT - finishing
- ablate PUCT terms, trim down to just parallelism/mate improvements, confidently measure what helps
- need long long search time parameter optimization for 1.25+ constant, e.g. applying similar to new terms
- try UCI move diversity again, maybe visit% threshold param, maybe first N moves param, optimize

PUCT - later
- try use saturation point of visits/ucb to extend 800 simulations or UCI time control if visits would exceed current best
	- could this also be used earlier during search, backpropagate up a pending/bounty value via separate field to be replaced
	  by actual backprops - set it up when saturation point would take from below 1st to 1st in visits
- add move diversity temperature to mini-tournament optimization (may need lots of data, maybe soft-finish other params first)

UCI
- manually dig into/debug STS strength drop with higher parallelism (1*16 vs. 2*256)
	- maybe enforce a threshold from 1st parallel PUCT to Nth after virtual losses - if too much lower, don't backprop
- tail Backpropagate into BackpropagateVisitsOnly
- workaround for .exe vs. non in ChessBase - can we probe for virtuals and activate before initializing python?
- spin option min/max
- set prediction cache size (hash size) by MiB - more consistent with other engines, already mostly supported
- cache-as-TT - do we add repetition state (1-rep vs. 2-rep) and/or no-progress count for current position (bucketed?)?

GPU/multi-GPU
- check out cloud multi-GPU options and set up/optimize (mirrored training + self-play + UCI)
- re-test everything on local/GPU and add comments for appropriate config for both (or implement HW-dependent config)
	- student on GPU, 4*256, teacher/student(which?) on TPU, 16*256 for both
	- make sure multi-GPU-on-desktop is supported - reevaluate params

Code quality
- need to add (tensorflow-text + sentencepiece + tf-models-official) to prepare.sh, etc., once TPU VM fixes are deployed
- copy config.toml from install->user on run (if not present) - optimized for dev iteration atm
- fix _ in network names - split on final _
- privatize C++ methods (got too python-brained)
- check for any unnecessary move constructors
- StrengthTestNetwork (naming)
- consolidate exception types in C++ and Python

Deployment
- re-test on fresh VMs
	- test without any virtual env on windows too, and with non-conda venv
- installers, instructions, progress indicators, error handling, etc.
- linux unit test script
- add windows command line build script, binplace somewhere cleanly

Publishing
- write-ups
- final network weights, optimization run (30s move tournament mode)
- website - game-in-10, one at a time, people can watch, comments shown for each move

Won't do
- TensorRT or TF C++ API (overly complicated setup, especiallly building TF on Windows, embarrassingly bad)
- Mixed precision (depends on specific hardware, complicates code)
- Richer UCI features like multiPV or ponder
- contempt (self-play or UCI)
- ~100MB-sized chunks
	- complicated by supervised vs. self-play size, and time between networks for small self-play clusters
	- BigTable is an alternative if training needs to scale up to pods
- playout cap randomization (Wu)
	- great concept but greatly complicates training data compression, code, prefer simplicity in this trade-off
- finish-fast utility score added to win score a la SAI/Wu/lc0
	- useful to help with dithering, especially late-game, but not meeting the bar
- alpha manager improvements
	- allow for some roles to be broken/unassigned rather than bailing out
	- prioritize trainer over players, cannibalize
	- try delays rather than broken marker for tpus in case of temporary failures, throttling
- cyclic learning rate and/or fast-SWA (too much complexity too late)
- performance
	- TF profiling - just live with what we have, v3-8 alpha TPUs decent as-is, not worth investment until more stable tooling, not using C++ inference anyway
	- use hard-elimination to deallocate sub-trees while searching
	- validation log still 11-12s after training log on cluster, try prefetch harder or debug
- training improvements (too expensive with remaining time/resources)
	- pseudonegatives (look up the paper again, may be difficult/impossible for chess, invalid positions)
	- investigate FROST - need to read more, but applied to data efficiency, seems like we could go in a couple directions:
		- use as intended, grab a bunch of unlabeled games, gradually pseudo-label better (end up with more data)
		- treat existing labels as pseudo-labels (e.g. poor-confidence value-from-final-result) and refine (end up with improved label quality)
	- try knowledge distillation for regression ideas: http://www.cs.ox.ac.uk/files/11078/ICCV19_Distilling_Knowledge_From_a_Deep_Pose_Regressor_Network.pdf
- GUI (analysis workflow is good enough inverted)
	- invert uci/gui relationship after working out in-proc/out details
		- switch between database/UCI modes
		- browse EPDs
		- set up positions (paste pgn, fen, move pieces, uci from database position)
		- go X buttons
	- change the square background rather than adding overlay, need more consistency between black/white squares
	- deal with info panel height/scrolling, move list
	- websocket reconnect
- PUCT ideas
	- many too expensive, difficult, volatile, etc.