###############################################################################
#                           Network configuration                             #
###############################################################################

[network]

network_name = "selfplay6a"
role = "train|play"

[[networks]]

    name = "selfplay6a"

    [networks.training]

    stages = [
        # Self-play
        { stage = "play" },

        # Train self-play, teacher then distill
        { stage = "train", target = "teacher" },
        { stage = "save", target = "teacher" },
        { stage = "train", target = "student" },
        { stage = "save", target = "student" },
        { stage = "save_swa", target = "student" },

        # Strength test (STS rating, etc.)
        { stage = "strength_test", target = "teacher" },
        { stage = "strength_test", target = "student" },
    ]

    games_path_training = "Games/Fresh2"

[[networks]]

    name = "chesscoach1"
    
    [networks.training]

    stages = [
        # Self-play
        { stage = "play" },

        # Train commentary and self-play, teacher
        { stage = "train_commentary", target = "teacher" },
        { stage = "train", target = "teacher" },
        { stage = "save", target = "teacher" },

        # Distill self-play to student
        { stage = "train", target = "student" },
        { stage = "save", target = "student" },
        { stage = "save_swa", target = "student" },

        # Strength test (STS rating, etc.)
        { stage = "strength_test", target = "teacher" },
        { stage = "strength_test", target = "student" },
    ]

[[networks]]

    name = "supervised1"
    
    [networks.training]

    num_games = 2_000_000
    window_size = 2_000_000

    value_loss_weight = 0.1
    mcts_value_loss_weight = 0.015

    stages = [
        # Train supervised, teacher
        { stage = "train", target = "teacher" },
        { stage = "save", target = "teacher" },

        # Strength test (STS rating, etc.)
        { stage = "strength_test", target = "teacher" },
    ]

    games_path_training = "Games/Supervised"

[[networks]]

    name = "commentary1"
    
    [networks.training]

    stages = [
        # Train commentary, teacher
        { stage = "train_commentary", target = "teacher" },
        { stage = "save", target = "teacher" },
    ]

    [networks.training.commentary_learning_rate_schedule]

    steps = [0] #[0, 800_000, 2_400_000, 4_000_000]
    rates = [2e-2] #[2e-2, 2e-3, 2e-4, 2e-5]

[[networks]]

    name = "benchmark1"

    [networks.training]

    stages = [
        # Self-play
        { stage = "play", window_size = 1_000_000, num_games = 1_440_000 },
    ]

    games_path_training = "Games/Benchmark"

    # NOTE: Still need to (a) turn off prediction cache if network untrained or testing without, (b) turn off uniform predictions if steps <= 0

###############################################################################
#     Default training and self-play configuration. Networks can override.    #
###############################################################################

[training]

architecture = "conv2d"
num_games = 44_000_000
window_size = 1_000_000
batch_size = 512
commentary_batch_size = 64
steps = 5_600_000 # Equivalent to 700,000 steps of batch size 4096
warmup_steps = 1000
pgn_interval = 10000
validation_interval = 2000
checkpoint_interval = 10000
strength_test_interval = 40000
steps_per_execution = 50
value_loss_weight = 1.0
mcts_value_loss_weight = 0.15
policy_loss_weight = 1.0
momentum = 0.9
dataset_shuffle_positions_training = 524_288 # 2^19 (~9.5 GiB, 19504 bytes payload per position)
dataset_shuffle_positions_validation = 4096 # 2^12
dataset_keep_game_proportion = 0.2
dataset_keep_position_proportion = 0.1
dataset_parallel_reads = 32
swa_decay = 0.5 # Good in practice for 10k-checkpoints - adjust geometrically for different checkpoint sizes.
swa_minimum_contribution = 0.01 # Proportion, determines number of network checkpoints to average on resume.
swa_batchnorm_steps = 4000 # Becomes 500 actual steps on TPU. With default 0.99 batch normalization momentum, tested to be enough.
vocabulary_filename = "vocabulary.txt"
games_path_training = "Games/Training"
games_path_validation = "Games/Validation"
commentary_path_training = "Commentary/Supervised"
commentary_path_validation = ""
wait_milliseconds = 300_000 # Check on Google Storage every 5 minutes when waiting for other machines.
stages = []

[training.learning_rate_schedule]

steps = [0, 800_000, 2_400_000, 4_000_000] # Equivalent to 100,000, 300,000, 500,000 with batch size 4096
rates = [2.5e-2, 2.5e-3, 2.5e-4, 2.5e-5] # Multiplied by device_count

[training.commentary_learning_rate_schedule]

steps = [0] #[0, 800_000, 2_400_000, 4_000_000] # Equivalent to 100,000, 300,000, 500,000 with batch size 4096
rates = [2e-4] #[2e-4, 2e-5, 2e-6, 2e-7] # Multiplied by device_count

[self_play]

# Instead of using the latest weights found for "network_name", use these specific ones; e.g., selfplay6a_001000000.
network_weights = ""

num_workers = 8
prediction_batch_size = 512

num_sampling_moves = 30
max_moves = 512
num_simulations = 800

root_dirichlet_alpha = 0.3
root_exploration_fraction = 0.25

exploration_rate_base = 19652.0
exploration_rate_init = 1.25

linear_exploration_rate = 500.0
linear_exploration_base = 10000.0
virtual_loss_coefficient = 1.25
moving_average_build = 0.95
moving_average_cap = 1500.0
backpropagation_puct_threshold = 0.025

wait_for_updated_network = false

###############################################################################
#                       Miscellaneous configuration                           #
###############################################################################

[prediction_cache]

request_gibibytes = 8
min_gibibytes = 1
max_ply = 24

[time_control]

safety_buffer_milliseconds = 25
fraction_remaining = 20

[search]

search_threads = 2
search_parallelism = 256
gui_update_interval_nodes = 1000

[storage]

games_per_chunk = 2000

[paths]

# With the below config, a network may be saved to "gs://chesscoach-eu/ChessCoach/Networks/network_000001000".
tpu_data_root = "gs://chesscoach-eu/ChessCoach"

networks = "Networks"
tensorboard = "TensorBoard"
logs = "Logs"
pgns = "Pgns"
optimization = "Optimization"
alpha_manager = "AlphaManager"

strength_test_marker_prefix = "StrengthTestComplete"

[optimization]

epd = "Arasan21.epd"
nodes = 100_000
failure_nodes = 10_000_000
position_limit = 10
log_interval = 10
plot_interval = 10

[optimization.parameters]

# Updates are only seen by C++. Custom propagation is needed if Python needs to see an update.
linear_exploration_rate = '(500.0, 5000.0)'
linear_exploration_base = '(1000.0, 50000.0)'
virtual_loss_coefficient = '(0.5, 2.0)'
moving_average_build = '(0.5, 1.0)'
moving_average_cap = '(100.0, 5000.0)'
backpropagation_puct_threshold = '(0.0, 0.1)'

[uci_options]

# Updates are only seen by C++. Custom propagation is needed if Python needs to see an update.
# Some options can only be set before initialization; e.g., search threads and parallelism.
network_weights = "string"
search_threads = "spin"
search_parallelism = "spin"

###############################################################################